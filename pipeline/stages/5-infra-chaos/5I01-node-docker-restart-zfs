#!/bin/bash

## Define and initialize test-result specific variables.
app_deploy_rc_val=1
app_loadgen_rc_val=1
zfs_docker_restart_rc_val=1

## SSH into the cluster to run the kubernetes jobs for the experiments
connect_cluster() {
mkdir -p /root/.ssh
touch /root/.ssh/id_rsa
echo "$SSH_KEYS" > /root/.ssh/id_rsa
chmod 600 /root/.ssh/id_rsa

### Taint the node to run infra chaos test scripts
node_name=$(ssh -o StrictHostKeyChecking=no $zfs_user@$zfs_ip -p $zfs_port -i /root/.ssh/id_rsa -o LogLevel=ERROR kubectl get nodes --no-headers | grep -v master | awk 'FNR==1 {print $1}')
ssh -o StrictHostKeyChecking=no $zfs_user@$zfs_ip -p $zfs_port -i /root/.ssh/id_rsa -o LogLevel=ERROR "kubectl taint nodes $node_name infra-aid=observer:NoSchedule"
ssh -o StrictHostKeyChecking=no $zfs_user@$zfs_ip -p $zfs_port -i /root/.ssh/id_rsa -o LogLevel=ERROR "mkdir infra && echo $node_name >> infra/node_name"

ssh -o StrictHostKeyChecking=no $zfs_user@$zfs_ip -p $zfs_port -i /root/.ssh/id_rsa -o LogLevel=ERROR 'cd e2e-nativek8s && bash pipeline/stages/5-infra-chaos/5I01-node-docker-restart-zfs run_job '"'$CI_JOB_ID'"'' '"'$CI_PIPELINE_ID'"' '"'$CI_COMMIT_SHA'"' '"'$node_name'"' '"'$ZFS_OPERATOR_NAMESPACE'"'

}

#######################################
# Deploy percona application on ZFSPV #
#######################################

app_deploy() {

job_id=$(echo $1)
pipeline_id=$(echo $2)
commit_id=$(echo $3)
observer_node=$4
zfs_operator_namespace=$(echo $5)
source ~/.profile
gittoken=$(echo "$github_token")

time="date"
current_time=$(eval $time)

## Pooling over the previous job to wait for its completion
bash pipeline/utils/zfs-e2e-cr jobname:node-docker-restart-zfs jobphase:Waiting
bash pipeline/utils/zfs-e2e-cr jobname:node-kubelet-restart-zfs jobphase:Waiting
bash pipeline/utils/zfs-e2e-cr jobname:node-failure-zfs jobphase:Waiting
bash pipeline/utils/zfs-e2e-cr jobname:node-docker-restart-zfs jobphase:Running init_time:"$current_time" jobid:"$job_id" pipelineid:"$pipeline_id" testcaseid:"$case_id"

## Generate the test name for running the litmusbook for percona deployment
test_name=$(bash pipeline/utils/generate_test_name testcase=percona-provision-zfs-docker metadata='')
echo $test_name

## copy the content of provisioner run_e2e_test.yml into a temporary file to update the test specific parameters.
cd zfs-localpv/e2e-tests
cp apps/percona/deployers/run_e2e_test.yml percona_zfs_docker.yml

# Modify test specific values in runner file using sed command
sed -i -e "/name: APP_NAMESPACE/{n;s/value: 'percona'/value: 'zfs-docker'/g}" \
-e 's/generateName: percona-deploy-/generateName: percona-provision-zfs-docker-restart-/g' \
-e 's/app: percona-deployment/app: percona-provision-zfs-docker-restart/g' percona_zfs_docker.yml

cat percona_zfs_docker.yml

## Run the Litmus job and get the details of the litmus job from litmus_job_runner utils.
bash ../../pipeline/utils/e2e_job_runner label='app:percona-provision-zfs-docker-restart' job=percona_zfs_docker.yml
## Get the cluster state Once the litmus jobs completed.
bash ../../pipeline/utils/dump_cluster_state;
cd ../..
## Update the e2e event for the job.
bash pipeline/utils/event_updater jobname:node-docker-restart-zfs $test_name jobid:"$job_id" pipelineid:"$pipeline_id" testcaseid:"$case_id"

app_deploy_rc_val=$(echo $?)
if [ "$app_deploy_rc_val" != "0" ]; then
exit 1;
fi

}

###################################
# Loadgen on Percona application  #
###################################

app_loadgen() {

## Generate test name for running litmusbook for generate load on application
test_name=$(bash pipeline/utils/generate_test_name testcase=percona-loadgen-zfs-docker metadata='')
echo $test_name
cd zfs-localpv/e2e-tests

# copy the content of workload run_e2e_test.yml into a different file to update the test specific parameters.
cp apps/percona/workload/run_e2e_test.yml loadgen_zfs_docker.yml

# Modify test specific values in runner file using sed command
sed -i -e 's/loadgen: percona-loadjob/loadgen: percona-loadjob-zfs-docker/g' \
-e 's/generateName: percona-loadgen-/generateName: percona-loadgen-zfs-docker-/g' \
-e "/name: APP_NAMESPACE/{n;s/value: 'percona'/value: 'zfs-docker'/g}" loadgen_zfs_docker.yml

cat loadgen_zfs_docker.yml

## Run the Litmus job and get the details of the litmus job from litmus_job_runner utils.
bash ../../pipeline/utils/e2e_job_runner label='loadgen:percona-loadjob-zfs-docker' job=loadgen_zfs_docker.yml
## Get the cluster state Once the litmus jobs completed.
bash ../../pipeline/utils/dump_cluster_state;
cd ../..
## Update the e2e event for the job.
bash pipeline/utils/event_updater jobname:node-docker-restart-zfs $test_name jobid:"$job_id" pipelineid:"$pipeline_id" testcaseid:"$case_id"

app_loadgen_rc_val=$(echo $?)
if [ "$app_loadgen_rc_val" != "0" ]; then
exit 1;
fi

}

##################################
#  Perform docker-restart test   #
##################################

zfs_docker_restart() {

## Generate the test name for running the litmusbook for percona deployment
run_id="zfs";test_name=$(bash pipeline/utils/generate_test_name testcase=docker-service-failure metadata=${run_id})
echo $test_name

## copy the content of run_e2e_test.yml into a temporary file to update the test specific parameters.
cd zfs-localpv/e2e-tests
cp experiments/infra-chaos/service_failure/run_e2e_test.yml run_zfs_docker_restart.yml

# Modify test specific values in runner file using sed command
sed -i -e "/name: ZFS_OPERATOR_NAMESPACE/{n;s/.*/            value: ${zfs_operator_namespace}/g}" \
-e 's/generateName: service-failure-chaos-/generateName: zfs-docker-service-restart-/g' \
-e 's/name: service-failure-chaos/name: zfs-docker-service-restart/g' \
-e '/name: APP_NAMESPACE/{n;s/.*/            value: zfs-docker/g}' \
-e '/name: APP_LABEL/{n;s/.*/            value: app=percona/g}' \
-e '/name: USERNAME/{n;s/.*/            value: k8s/g}' \
-e '/name: APP_PVC/{n;s/.*/            value: percona-pvc/g}' \
-e '/name: SVC_TYPE/{n;s/.*/            value: docker/g}' \
-e 's/password:/password: VGVzdEAxMjM=/g' \
-e '/name: DATA_PERSISTENCE/{n;s/.*/            value: mysql/}' run_zfs_docker_restart.yml

sed -i -e "s|#nodeSelector|nodeSelector|g" \
-e "s|#  kubernetes.io/hostname:|  kubernetes.io/hostname: ${observer_node}|g" run_zfs_docker_restart.yml

sed -i '/parameters.yml: |/a \
    dbuser: root\
    dbpassword: k8sDem0\
    dbname: zfs_docker_restart
' run_zfs_docker_restart.yml

sed -i '/command:/i \
          - name: RUN_ID\
            value: '"$run_id"'\
' run_zfs_docker_restart.yml

cat run_zfs_docker_restart.yml

## Run the Litmus job and get the details of the litmus job from litmus_job_runner utils.
bash ../../pipeline/utils/e2e_job_runner label='name:zfs-docker-service-restart' job=run_zfs_docker_restart.yml
## Get the cluster state Once the litmus jobs completed.
bash ../../pipeline/utils/dump_cluster_state;
cd ../..
## Update the e2e event for the job.
bash pipeline/utils/event_updater jobname:node-docker-restart-zfs $test_name jobid:"$job_id" pipelineid:"$pipeline_id" testcaseid:"$case_id"

zfs_docker_restart_rc_val=$(echo $?)
if [ "$zfs_docker_restart_rc_val" != "0" ]; then
exit 1;
fi

}

##########################
# Deprovision Application#
##########################

app_deprovision() {
  
## Generate test name to run litmusbook for deprovisioning the percona application
test_name=$(bash pipeline/utils/generate_test_name testcase=percona-deprovision-zfs-docker metadata='')
echo $test_name
cd zfs-localpv/e2e-tests

# copy the content of run_e2e_test.yml into a different file to update the test specific parameters.
cp apps/percona/deployers/run_e2e_test.yml percona_zfs_docker_deprovision.yml

# Modify test specific values in runner file using sed command
sed -i -e "/name: APP_NAMESPACE/{n;s/value: 'percona'/value: 'zfs-docker'/g}" \
-e 's/app: percona-deployment/app: percona-deprovision-zfs-docker-restart/g' \
-e 's/generateName: percona-deploy-/generateName: percona-deprovision-zfs-docker-restart-/g' \
-e "s/value: 'provision'/value: 'deprovision'/g" percona_zfs_docker_deprovision.yml

cat percona_zfs_docker_deprovision.yml

## Run the Litmus job and get the details of the litmus job from litmus_job_runner utils.
bash ../../pipeline/utils/e2e_job_runner label='app:percona-deprovision-zfs-docker-restart' job=percona_zfs_docker_deprovision.yml
## Get the cluster state Once the litmus jobs completed.
bash ../../pipeline/utils/dump_cluster_state;
cd ../..
## Update the e2e event for the job.
bash pipeline/utils/event_updater jobname:node-docker-restart-zfs $test_name jobid:"$job_id" pipelineid:"$pipeline_id" testcaseid:"$case_id"

app_deprovision_rc_val=$(echo $?)

if [ "$app_deprovision_rc_val" -eq "0" ] &&
   [ "$zfs_docker_restart_rc_val" -eq "0" ] &&
   [ "$app_loadgen_rc_val" -eq "0" ] &&
   [ "$app_deploy_rc_val" -eq "0" ]; then

## Update the e2e-result-custom-resources for the job
bash pipeline/utils/zfs-e2e-cr jobname:node-docker-restart-zfs jobphase:Completed end_time:"$current_time" jobid:"$job_id" pipelineid:"$pipeline_id" testcaseid:"$case_id" test_result:Pass
#python3 openebs-nativek8s/utils/result/result_update.py $job_id 5I01 5-infra-chaos "Restart the docker services on application node and check the behaviour of zfs-localpv" Pass $pipeline_id "$current_time" $commit_id $gittoken

else
## Update the e2e-result-custom-resources for the job
bash pipeline/utils/zfs-e2e-cr jobname:node-docker-restart-zfs jobphase:Completed end_time:"$current_time" jobid:"$job_id" pipelineid:"$pipeline_id" testcaseid:"$case_id" test_result:Fail
#python3 openebs-nativek8s/utils/result/result_update.py $job_id 5I01 5-infra-chaos "Restart the docker services on application node and check the behaviour of zfs-localpv" Fail $pipeline_id "$current_time" $commit_id $gittoken
exit 1;
fi

}


if [ "$1" == "run_job" ];then
  app_deploy $2 $3 $4 $5 $6
  app_loadgen
  zfs_docker_restart
  app_deprovision
else
  connect_cluster
fi